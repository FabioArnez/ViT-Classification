{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT Module Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL as Image\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTConfig\n",
    "from .vit_model import VisionTransformer\n",
    "from .vit_module import ViTConfigExtended\n",
    "from .vit_module import VisionTransformerModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define ViT-Config: type and structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_config = ViTConfigExtended(vit_model_type='ViT-B',\n",
    "                               patch_size=16,\n",
    "                               num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| vit_config: ViTConfigExtended {\n",
      "                  \"attention_probs_dropout_prob\": 0.0,\n",
      "                  \"encoder_stride\": 16,\n",
      "                  \"hidden_act\": \"gelu\",\n",
      "                  \"hidden_dropout_prob\": 0.0,\n",
      "                  \"hidden_size\": 768,\n",
      "                  \"image_size\": 224,\n",
      "                  \"initializer_range\": 0.02,\n",
      "                  \"intermediate_size\": 3072,\n",
      "                  \"layer_norm_eps\": 1e-12,\n",
      "                  \"loss_fn\": \"cross_entropy\",\n",
      "                  \"max_nro_epochs\": 10,\n",
      "                  \"model_type\": \"vit\",\n",
      "                  \"num_attention_heads\": 12,\n",
      "                  \"num_channels\": 3,\n",
      "                  \"num_classes\": 10,\n",
      "                  \"num_hidden_layers\": 12,\n",
      "                  \"optimizer_lr\": 0.0001,\n",
      "                  \"optimizer_weight_decay\": 1e-05,\n",
      "                  \"patch_size\": 16,\n",
      "                  \"qkv_bias\": true,\n",
      "                  \"transformers_version\": \"4.44.2\",\n",
      "                  \"vit_model_type\": \"ViT-B\"\n",
      "                }\n"
     ]
    }
   ],
   "source": [
    "ic(vit_config);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create ViT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_model_module = VisionTransformerModule(config=vit_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| vit_model_module: VisionTransformerModule(\n",
      "                        (model): VisionTransformer(\n",
      "                          (model): ViT(\n",
      "                            (to_patch_embedding): Sequential(\n",
      "                              (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=16, p2=16)\n",
      "                              (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                              (2): Linear(in_features=768, out_features=768, bias=True)\n",
      "                              (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                            )\n",
      "                            (dropout): Dropout(p=0.0, inplace=False)\n",
      "                            (transformer): Transformer(\n",
      "                              (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                              (layers): ModuleList(\n",
      "                                (0-11): 12 x ModuleList(\n",
      "                                  (0): Attention(\n",
      "                                    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                                    (attend): Softmax(dim=-1)\n",
      "                                    (dropout): Dropout(p=0.0, inplace=False)\n",
      "                                    (to_qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
      "                                    (to_out): Sequential(\n",
      "                                      (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "                                      (1): Dropout(p=0.0, inplace=False)\n",
      "                                    )\n",
      "                                  )\n",
      "                                  (1): FeedForward(\n",
      "                                    (net): Sequential(\n",
      "                                      (0): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "                                      (1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                                      (2): GELU(approximate='none')\n",
      "                                      (3): Dropout(p=0.0, inplace=False)\n",
      "                                      (4): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                                      (5): Dropout(p=0.0, inplace=False)\n",
      "                                    )\n",
      "                                  )\n",
      "                                )\n",
      "                              )\n",
      "                            )\n",
      "                            (to_latent): Identity()\n",
      "                            (mlp_head): Linear(in_features=768, out_features=10, bias=True)\n",
      "                          )\n",
      "                        )\n",
      "                        (train_acc): MulticlassAccuracy()\n",
      "                        (val_acc): MulticlassAccuracy()\n",
      "                        (test_acc): MulticlassAccuracy()\n",
      "                        (loss_fn): CrossEntropyLoss()\n",
      "                      )\n"
     ]
    }
   ],
   "source": [
    "ic(vit_model_module);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "min-sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
